{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd62f5f5",
   "metadata": {},
   "source": [
    "### Validação\n",
    "**1. Train/test split**\n",
    "\n",
    "If one subset of our data only have people of a certain age or income levels, we can bias our estimate. This is typically referred to as a **sampling bias:** Sampling bias is systematic error due to a non-random sample of a population, causing some members of the population to be less likely to be included than others, resulting in a biased sample.\n",
    "\n",
    "```\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "```\n",
    "\n",
    "**2. k-Fold Cross-Validation (k-Fold CV)**\n",
    "\n",
    "To minimize sampling bias we can think about another approach. k-Fold CV splits the data into $k$ folds, then trains the data on $k-1$ folds and test on the one fold that was left out. It does this for all combinations and averages the result on each instance.\n",
    "\n",
    "```\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "```\n",
    "\n",
    "Mas é possível usar Pipelines que façam a validação cruzada, sem precisar varrer cada Fold com um `for` (https://towardsdatascience.com/validating-your-machine-learning-model-25b4c8643fb7):\n",
    "\n",
    "```\n",
    "p_grid = {\"C\": [1, 10, 100], \"gamma\": [.01, .1]}                  # parameters\n",
    "svr = SVC(kernel=\"rbf\")                                           # model\n",
    "inner_cv = KFold(n_splits=2, shuffle=True, random_state=42)       # K-Fold for GridSearchCV (params selection)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)       # K-Fold for computing metrics\n",
    "\n",
    "# GridSearchCV does inner K-Fold to select best params in p_grid\n",
    "clf = GridSearchCV(estimator=svr, param_grid=p_grid, cv=inner_cv)\n",
    "\n",
    "# cross_val_score does outer K-Fold to compute the metrics of the model\n",
    "nested_score = cross_val_score(clf, X=X_iris, y=y_iris, cv=outer_cv, scoring=\"neg_mean_squared_error\").mean() \n",
    "print(nested_score)\n",
    "```\n",
    "\n",
    "`cross_val_score` usa o score que for passado em `scoring`, se for `None` passa o scoring padrão do estimador. Conferir https://scikit-learn.org/stable/modules/model_evaluation.html com as métricas que ele calcula e as respectivas strings.\n",
    "\n",
    "A função `cross_validate` permite passar vários scores para serem computados no K-fold através do parâmetro `scoring=('r2', 'neg_mean_squared_error')`. Usa as mesmas strings do link anterior.\n",
    "\n",
    "**3. Leave-one-out Cross-Validation (LOOCV)**\n",
    "\n",
    "Uses each sample in the data as a separate test set while all remaining samples form the training set. This variant is identical to k-fold CV when k = n (number of observations).\n",
    "\n",
    "```\n",
    "loo = LeaveOneOut()\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "```\n",
    "\n",
    "Computationally very costly as the model needs to be trained n times. Only do this if the data is small.\n",
    "\n",
    "**4. Leave-one-group-out Cross-Validation (LOGOCV)**\n",
    "\n",
    "You might want each fold to only contain a single group. For example, let’s say you have a dataset of 20 companies and their clients and you want to predict the success of these companies.\n",
    "\n",
    "To keep the folds “pure” and only contain a single company you would create a fold for each company. That way, you create a version of k-Fold CV and LOOCV where you leave one company/group out.\n",
    "\n",
    "```\n",
    "logo = LeaveOneGroupOut()\n",
    "for train_index, test_index in logo.split(X, y, groups):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "```\n",
    "\n",
    "**5. Time Series CV**\n",
    "\n",
    "Overfitting would be a major concern since your training data could contain information from the future. It is important that all your training data happens before your test data.\n",
    "\n",
    "One way of validating time series data is by using k-fold CV and making sure that in each fold the training data takes place before the test data.\n",
    "\n",
    "```\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "```\n",
    "\n",
    "**6. Model comparisons**\n",
    "\n",
    "(https://towardsdatascience.com/validating-your-machine-learning-model-25b4c8643fb7)\n",
    "\n",
    "* Wilcoxon signed-rank test\n",
    "* McNemar’s test\n",
    "* 5x2CV paired t-test\n",
    "* 5x2CV paired F-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bd8c2b",
   "metadata": {},
   "source": [
    "### Pipeline:\n",
    "Sequentially apply a list of transforms and a final estimator. Intermediate steps of pipeline must implement fit and transform methods and the final estimator only needs to implement fit (https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976).\n",
    "\n",
    "```\n",
    "steps = [('scaler', StandardScaler()), ('SVM', SVC())]\n",
    "pipeline = Pipeline(steps)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2, random_state=30, stratify=Y)\n",
    "parameteres = {'SVM__C':[0.001,0.1,10,100,10e5], 'SVM__gamma':[0.1,0.01]}\n",
    "grid = GridSearchCV(pipeline, param_grid=parameteres, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"score = %3.2f\" %(grid.score(X_test,y_test)))\n",
    "print(grid.best_params_)\n",
    "```\n",
    "\n",
    "The strings (‘scaler’, ‘SVM’) can be anything, as these are just names to identify clearly the transformer or estimator. We can use `make_pipeline` instead of Pipeline to avoid naming the estimator or transformer. The final step has to be an estimator in this list of tuples.\n",
    "\n",
    "Other example using other components in the Pipeline (https://medium.com/data-hackers/como-usar-pipelines-no-scikit-learn-1398a4cc6ae9): a OHE, an imputer, a model:\n",
    "\n",
    "```\n",
    "# dividindo em conjunto de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['Survived'], axis=1), \n",
    "                                                    df['Survived'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# criando o modelo usando pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('one-hot encoder', OneHotEncoder()),\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('tree', DecisionTreeClassifier(max_depth=3, random_state=0))\n",
    "])\n",
    "\n",
    "# treinando o modelo\n",
    "model.fit(X_train, y_train)\n",
    "train_score = model.score(X_train, y_train)\n",
    "\n",
    "# avaliando o modelo\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "# validando o modelo usando 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = cross_validate(model, X=df.drop(['Survived'], axis=1), y=df['Survived'], cv=kfold)\n",
    "print(\"Average accuracy: %f (%f)\" %(results['test_score'].mean(), results['test_score'].std()))\n",
    "```\n",
    "\n",
    "A função `cross_validate` permite passar vários scores para serem computados no K-fold através do parâmetro `scoring=('r2', 'neg_mean_squared_error')`\n",
    "\n",
    "**Why Pipeline?**\n",
    "One could proceed like that, without Pipeline:\n",
    "```\n",
    "scale = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scale.transform(X_train)\n",
    "grid = GridSearchCV(SVC(), param_grid=parameteres, cv=5)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "```\n",
    "_Problem:_ The scaled features used for cross-validation is separated into test and train fold but the test fold within grid-search already contains the info about training set, as the whole training set (`X_train`) was used for standardization. In a simpler note when `SVC.fit()` is done using cross-validation, the features already include info from the test-fold as **`StandardScaler.fit()` was done on the whole training set.**\n",
    "\n",
    "https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b9a6b",
   "metadata": {},
   "source": [
    "### Images\n",
    "**K-Fold**\n",
    "![./images/k-fold.png](./images/k-fold.png)\n",
    "**Leave-one-out**\n",
    "![./images/leave-one-out.png](./images/leave-one-out.png)\n",
    "**Leave-one-group-out**\n",
    "![./images/leave-one-group-out.png](./images/leave-one-group-out.png)\n",
    "**Nested CV**\n",
    "![./images/nested-cv.png](./images/nested-cv.png)\n",
    "**Time Series CV**\n",
    "![./images/time-series-cv.png](./images/time-series-cv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e320aba4",
   "metadata": {},
   "source": [
    "## Técnicas de validação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3388788",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/validating-your-machine-learning-model-25b4c8643fb7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a83c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "(X_train, X_test, \n",
    " y_train, y_test) = train_test_split(X, y, test_size=0.3, \n",
    "                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3de1eaaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=4.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10112/3760865569.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mkf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    328\u001b[0m                 (\"Cannot have number of splits n_splits={0} greater\"\n\u001b[0;32m    329\u001b[0m                  \" than the number of samples: n_samples={1}.\")\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=4."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d336cb",
   "metadata": {},
   "source": [
    "Exemplo legal do uso do K-Fold + GridSearchCV + cálculo de métrica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bbd13ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "\n",
    "# Load the dataset\n",
    "X_iris = load_iris().data\n",
    "y_iris = load_iris().target\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"C\": [1, 10, 100],\n",
    "          \"gamma\": [.01, .1]}\n",
    "\n",
    "# We will use a Support Vector Classifier with \"rbf\" kernel\n",
    "svr = SVC(kernel=\"rbf\")\n",
    "\n",
    "# Create inner and outer strategies\n",
    "inner_cv = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Pass the gridSearch estimator to cross_val_score\n",
    "clf = GridSearchCV(estimator=svr, param_grid=p_grid, cv=inner_cv)\n",
    "nested_score = cross_val_score(clf, X=X_iris, y=y_iris, cv=outer_cv).mean()\n",
    "print(nested_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f010f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7617818f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2967: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6766573217164245"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Load the dataset\n",
    "X = load_iris().data\n",
    "y = load_iris().target\n",
    "\n",
    "# Prepare models and select your CV method\n",
    "model1 = ExtraTreesClassifier()\n",
    "model2 = RandomForestClassifier()\n",
    "kf = KFold(n_splits=20, random_state=42, shuffle=True)\n",
    "\n",
    "# Extract results for each model on the same folds\n",
    "results_model1 = cross_val_score(model1, X, y, cv=kf)\n",
    "results_model2 = cross_val_score(model2, X, y, cv=kf)\n",
    "\n",
    "# Calculate p value\n",
    "stat, p = wilcoxon(results_model1, results_model2, zero_method='zsplit'); p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23f93fb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10112/1649151097.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmcnemar_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmcnemar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# The correct target (class) labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m y_target = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mlxtend.evaluate import mcnemar_table, mcnemar\n",
    "\n",
    "# The correct target (class) labels\n",
    "y_target = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Class labels predicted by model 1\n",
    "y_model1 = np.array([0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
    "                     0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1])\n",
    "\n",
    "# Class labels predicted by model 2\n",
    "y_model2 = np.array([0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
    "                     1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0])\n",
    "\n",
    "# Calculate p value\n",
    "tb = mcnemar_table(y_target=y_target, \n",
    "                   y_model1=y_model1, \n",
    "                   y_model2=y_model2)\n",
    "chi2, p = mcnemar(ary=tb, exact=True)\n",
    "\n",
    "print('chi-squared:', chi2)\n",
    "print('p-value:', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5170b391",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d255c2ba",
   "metadata": {},
   "source": [
    "Exemplo legal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "369bbe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "winedf = pd.read_csv('red-wine/winequality-red.csv', sep=',')\n",
    "print(winedf.isnull().sum()) # check for missing dataprint winedf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f6d72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = winedf.drop(['quality'],axis=1)\n",
    "Y = winedf['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8411b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95b5813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', StandardScaler()), ('SVM', SVC())]\n",
    "pipeline = Pipeline(steps) # define the pipeline object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92f5b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=30, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94216cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    681\n",
      "6    638\n",
      "7    199\n",
      "4     53\n",
      "8     18\n",
      "3     10\n",
      "Name: quality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(winedf['quality'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9637d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameteres = {'SVM__C':[0.001,0.1,10,100,10e5], 'SVM__gamma':[0.1,0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c71d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipeline, param_grid=parameteres, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57e9c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "597ca4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"score = %3.2f\" %(grid.score(X_test,y_test)))\n",
    "#print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996962dc",
   "metadata": {},
   "source": [
    "### Usando o dataset do Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50b4a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af1ac8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./titanic/train.csv\")\n",
    "test = pd.read_csv(\"./titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e822449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 12), (418, 11))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cc5b0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f24e54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e216e1",
   "metadata": {},
   "source": [
    "Vou selecionar somente os campos numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb8b8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.select_dtypes(include=['int64', 'float64'])\n",
    "test = test.select_dtypes(include=['int64', 'float64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "796b195d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare\n",
       "0            1         0       3  22.0      1      0   7.2500\n",
       "1            2         1       1  38.0      1      0  71.2833\n",
       "2            3         1       3  26.0      0      0   7.9250\n",
       "3            4         1       1  35.0      1      0  53.1000\n",
       "4            5         0       3  35.0      0      0   8.0500"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3979e259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Fare             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f0a658b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId     0\n",
       "Pclass          0\n",
       "Age            86\n",
       "SibSp           0\n",
       "Parch           0\n",
       "Fare            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad9dc6b",
   "metadata": {},
   "source": [
    "Vou imputar a média para todos os campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf94017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train.mean()\n",
    "train = train.fillna(mean)\n",
    "test = test.fillna(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a31c4558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Fare           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9290d63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Pclass         0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Fare           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5ac7e2",
   "metadata": {},
   "source": [
    "Vou executar estes passos:\n",
    "* Treinar um modelo de Random Forest, aplicando scaling nas features e fazendo feature selection com um GridSearchCV com K-Fold de 10 folds\n",
    "* Vou medir as métricas de precision, recall e ROC-AUC médias entre os folds de um K-Fold de 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf6a1f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e940d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"Survived\"])\n",
    "y_train = train[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "023eb4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('RF', RandomForestClassifier())]),\n",
       "             param_grid={'RF__max_depth': [5, 10],\n",
       "                         'RF__n_estimators': [100, 200]})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "p_grid = {\n",
    "    \"RF__n_estimators\": [100, 200],#[100, 250, 500, 1000],\n",
    "    \"RF__max_depth\": [5, 10],#[5, 10, 15],\n",
    "    #\"RF__min_samples_split\": [3, 4, 5],\n",
    "    #\"RF__min_samples_leaf\": [3, 4, 5]\n",
    "}\n",
    "inner_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "steps = [('scaler', StandardScaler()), ('RF', model)]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "clf = GridSearchCV(estimator=pipeline, param_grid=p_grid, cv=inner_cv) # cv=10\n",
    "results = cross_validate(\n",
    "    clf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=outer_cv, # cv=5\n",
    "    scoring=('precision', 'recall', 'roc_auc'),\n",
    "    return_train_score=True,\n",
    "    return_estimator=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00865b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(clf.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3a122d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([8.44775391, 9.16711807, 8.18568206, 8.37114978, 9.7367487 ]), 'score_time': array([0.05172563, 0.02063632, 0.03149652, 0.03138566, 0.03125095]), 'estimator': [GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
      "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                                       ('RF', RandomForestClassifier())]),\n",
      "             param_grid={'RF__max_depth': [5, 10],\n",
      "                         'RF__n_estimators': [100, 200]}), GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
      "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                                       ('RF', RandomForestClassifier())]),\n",
      "             param_grid={'RF__max_depth': [5, 10],\n",
      "                         'RF__n_estimators': [100, 200]}), GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
      "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                                       ('RF', RandomForestClassifier())]),\n",
      "             param_grid={'RF__max_depth': [5, 10],\n",
      "                         'RF__n_estimators': [100, 200]}), GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
      "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                                       ('RF', RandomForestClassifier())]),\n",
      "             param_grid={'RF__max_depth': [5, 10],\n",
      "                         'RF__n_estimators': [100, 200]}), GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
      "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                                       ('RF', RandomForestClassifier())]),\n",
      "             param_grid={'RF__max_depth': [5, 10],\n",
      "                         'RF__n_estimators': [100, 200]})], 'test_precision': array([0.71052632, 0.76744186, 0.71428571, 0.58      , 0.76666667]), 'train_precision': array([0.82666667, 0.79746835, 0.85314685, 0.99468085, 0.84137931]), 'test_recall': array([0.49090909, 0.52380952, 0.45454545, 0.51785714, 0.41818182]), 'train_recall': array([0.56880734, 0.6       , 0.53275109, 0.86175115, 0.55963303]), 'test_roc_auc': array([0.79607438, 0.79642857, 0.84624304, 0.67275748, 0.76541275]), 'train_roc_auc': array([0.87426488, 0.86676615, 0.87165926, 0.99318547, 0.87554733])}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0b5aaffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "              estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                        ('RF', RandomForestClassifier())]),\n",
       "              param_grid={'RF__max_depth': [5, 10],\n",
       "                          'RF__n_estimators': [100, 200]}),\n",
       " GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "              estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                        ('RF', RandomForestClassifier())]),\n",
       "              param_grid={'RF__max_depth': [5, 10],\n",
       "                          'RF__n_estimators': [100, 200]}),\n",
       " GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "              estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                        ('RF', RandomForestClassifier())]),\n",
       "              param_grid={'RF__max_depth': [5, 10],\n",
       "                          'RF__n_estimators': [100, 200]}),\n",
       " GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "              estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                        ('RF', RandomForestClassifier())]),\n",
       "              param_grid={'RF__max_depth': [5, 10],\n",
       "                          'RF__n_estimators': [100, 200]}),\n",
       " GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "              estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                        ('RF', RandomForestClassifier())]),\n",
       "              param_grid={'RF__max_depth': [5, 10],\n",
       "                          'RF__n_estimators': [100, 200]})]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dc1f2d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8626684071305114\n",
      "0.7077841114413942\n",
      "0.6245885221498533\n",
      "0.4810606060606061\n",
      "0.8962846174915786\n",
      "0.77538324350398\n"
     ]
    }
   ],
   "source": [
    "mean_train_precision = results[\"train_precision\"].mean()\n",
    "mean_test_precision = results[\"test_precision\"].mean()\n",
    "mean_train_recall = results[\"train_recall\"].mean()\n",
    "mean_test_recall = results[\"test_recall\"].mean()\n",
    "mean_train_roc_auc = results[\"train_roc_auc\"].mean()\n",
    "mean_test_roc_auc = results[\"test_roc_auc\"].mean()\n",
    "print(mean_train_precision)\n",
    "print(mean_test_precision)\n",
    "print(mean_train_recall)\n",
    "print(mean_test_recall)\n",
    "print(mean_train_roc_auc)\n",
    "print(mean_test_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "14fcccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf19244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# É o nosso resultado em cima do dataset de teste do Kaggle\n",
    "y_prob = clf.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0b4e4",
   "metadata": {},
   "source": [
    "Exemplo de https://stackoverflow.com/questions/53252156/standardscaler-with-pipelines-and-gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f412a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_MLPRegressor = Pipeline([('scaler',  StandardScaler()),\n",
    "            ('MLPRegressor', MLPRegressor(random_state = 42))])\n",
    "\n",
    "\n",
    "grid_params_MLPRegressor = [{\n",
    "    'MLPRegressor__solver': ['lbfgs'],\n",
    "    'MLPRegressor__max_iter': [100,200,300,500],\n",
    "    'MLPRegressor__activation' : ['relu','logistic','tanh'],\n",
    "    'MLPRegressor__hidden_layer_sizes':[(2,), (4,),(2,2),(4,4),(4,2),(10,10),(2,2,2)],\n",
    "}]\n",
    "\n",
    "\n",
    "CV_mlpregressor = GridSearchCV (estimator = pipe_MLPRegressor,\n",
    "                               param_grid = grid_params_MLPRegressor,\n",
    "                               cv = 5,return_train_score=True, verbose=0)\n",
    "\n",
    "CV_mlpregressor.fit(x_train, y_train)\n",
    "\n",
    "CV_mlpregressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ed5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "x,y = load_boston(return_X_y=True)\n",
    "\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y, random_state=6784)\n",
    "\n",
    "pipe_MLPRegressor = Pipeline([('scaler',  StandardScaler()),\n",
    "            ('MLPRegressor', MLPRegressor(random_state = 42))])\n",
    "grid_params_MLPRegressor = [{\n",
    "    'MLPRegressor__solver': ['lbfgs'],\n",
    "    'MLPRegressor__max_iter': [100,200,300,500],\n",
    "    'MLPRegressor__activation' : ['relu','logistic','tanh'],\n",
    "    'MLPRegressor__hidden_layer_sizes':[(2,), (4,),(2,2),(4,4),(4,2),(10,10),(2,\n",
    "2,2)],}]\n",
    "\n",
    "\n",
    "CV_mlpregressor = GridSearchCV (estimator = pipe_MLPRegressor,\n",
    "                               param_grid = grid_params_MLPRegressor,\n",
    "                               cv = 5,return_train_score=True, verbose=0)\n",
    "\n",
    "CV_mlpregressor.fit(xtrain, ytrain)\n",
    "\n",
    "ypred=CV_mlpregressor.predict(xtest)\n",
    "\n",
    "print np.c_[ytest, ypred]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
